{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874e3dea",
   "metadata": {},
   "source": [
    "# Deteción de riesgo de depresión/anxiety mediante ML (texto)\n",
    "\n",
    "**Notebook listo para ejecutar en Google Colab.**\n",
    "\n",
    "_Estructura:_ preprocesado, vectorización TF-IDF, modelos baseline (Logistic Regression), XGBoost, interpretabilidad (SHAP) y guardado de modelos.\n",
    "\n",
    "**Nota:** Este notebook asume un CSV con columnas `text` y `label` (0/1). Ajusta rutas/columnas según el dataset que uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e42b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de dependencias (ejecutar en Colab)\n",
    "!pip install -q scikit-learn xgboost shap kaggle nltk spacy joblib\n",
    "\n",
    "# Descargar modelo spaCy en inglés (comenta si no lo necesitas)\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principales\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, RocCurveDisplay, precision_recall_curve, auc\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))  # cambiar a 'spanish' si es necesario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a621d",
   "metadata": {},
   "source": [
    "## Descarga del dataset desde Kaggle (opcional)\n",
    "\n",
    "Sube tu `kaggle.json` a Colab y coloca en `~/.kaggle/kaggle.json`. Luego ejecuta la celda de abajo cambiando `<OWNER/DATASET>` por el identificador del dataset en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: descargar dataset desde Kaggle\n",
    "# Asegúrate de subir tu kaggle.json al entorno de Colab antes de ejecutar\n",
    "os.makedirs('/content/data/raw', exist_ok=True)\n",
    "# !kaggle datasets download -d <OWNER>/<DATASET-NAME> -p /content/data/raw --unzip\n",
    "\n",
    "# Si ya subiste un CSV manualmente, puedes copiarlo a /content/data/raw/data.csv\n",
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1620287",
   "metadata": {},
   "source": [
    "## Cargar datos\n",
    "\n",
    "Asegúrate de que el CSV esté en `/content/data/raw/` y que tenga columnas `text` y `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CSV (ajusta el nombre de archivo si procede)\n",
    "csv_path = '/content/data/raw/data.csv'  # cambia si el archivo tiene otro nombre\n",
    "if not os.path.exists(csv_path):\n",
    "    print(f\"Archivo {csv_path} no encontrado. Sube el dataset o ajusta la ruta.\")\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print('Shape:', df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6fc35",
   "metadata": {},
   "source": [
    "## Preprocesado de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(s, lang='en'):\n",
    "    s = str(s)\n",
    "    s = re.sub(r'http\\S+', ' ', s)\n",
    "    s = re.sub(r'@\\w+', ' ', s)\n",
    "    s = re.sub(r'[^A-Za-zÀ-ÖØ-öø-ÿ0-9\\s]', ' ', s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "# Aplicar limpieza si df existe\n",
    "if 'df' in globals():\n",
    "    if 'text' not in df.columns or 'label' not in df.columns:\n",
    "        print('Asegúrate de que el dataset contenga columnas \"text\" y \"label\"')\n",
    "    else:\n",
    "        df['text_clean'] = df['text'].apply(lambda x: clean_text(x))\n",
    "        df = df[df['text_clean'].str.len() > 10].reset_index(drop=True)\n",
    "        print('After cleaning, shape:', df.shape)\n",
    "        display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd746ea",
   "metadata": {},
   "source": [
    "## Exploración rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcdacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in globals():\n",
    "    print(df['label'].value_counts())\n",
    "    sns.countplot(x='label', data=df)\n",
    "    plt.title('Distribución de etiquetas')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9b681",
   "metadata": {},
   "source": [
    "## División train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in globals():\n",
    "    X = df['text_clean'].values\n",
    "    y = df['label'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.2, \n",
    "                                                        stratify=y, \n",
    "                                                        random_state=42)\n",
    "    print('Train:', X_train.shape[0], 'Test:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02951e",
   "metadata": {},
   "source": [
    "## Baseline: TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb27ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words=STOPWORDS)\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'))\n",
    "])\n",
    "\n",
    "if 'X_train' in globals():\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "    y_pred = pipe_lr.predict(X_test)\n",
    "    y_prob = pipe_lr.predict_proba(X_test)[:,1]\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('ROC AUC:', roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488f21f",
   "metadata": {},
   "source": [
    "## Modelo XGBoost (TF-IDF -> XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in globals():\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_tfidf, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_tfidf, label=y_test)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'eta': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(params, dtrain, num_boost_round=200, evals=[(dtest,'test')], early_stopping_rounds=20)\n",
    "    y_prob_xgb = bst.predict(dtest)\n",
    "    y_pred_xgb = (y_prob_xgb >= 0.5).astype(int)\n",
    "\n",
    "    print(classification_report(y_test, y_pred_xgb))\n",
    "    print('ROC AUC XGBoost:', roc_auc_score(y_test, y_prob_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4e085",
   "metadata": {},
   "source": [
    "## Interpretabilidad: SHAP (muestra pequeña)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bst' in globals():\n",
    "    # Para memoria, tomamos una muestra pequeña\n",
    "    sample_idx = np.random.choice(X_test_tfidf.shape[0], size=min(200, X_test_tfidf.shape[0]), replace=False)\n",
    "    X_shap = X_test_tfidf[sample_idx].toarray()\n",
    "    dmat_shap = xgb.DMatrix(X_shap)\n",
    "    explainer = shap.TreeExplainer(bst)\n",
    "    shap_values = explainer.shap_values(dmat_shap)\n",
    "\n",
    "    # Mostrar summary plot (puede tardar)\n",
    "    try:\n",
    "        feature_names = tfidf.get_feature_names_out()\n",
    "    except:\n",
    "        feature_names = [f'feat_{i}' for i in range(X_shap.shape[1])]\n",
    "    shap.summary_plot(shap_values, X_shap, feature_names=feature_names[:X_shap.shape[1]], plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11484dae",
   "metadata": {},
   "source": [
    "## Guardar modelos y artefactos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/content/models', exist_ok=True)\n",
    "if 'pipe_lr' in globals():\n",
    "    joblib.dump(pipe_lr, '/content/models/pipe_lr.pkl')\n",
    "if 'tfidf' in globals():\n",
    "    joblib.dump(tfidf, '/content/models/tfidf.pkl')\n",
    "if 'bst' in globals():\n",
    "    bst.save_model('/content/models/xgb_model.json')\n",
    "print('Modelos guardados en /content/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2403234",
   "metadata": {},
   "source": [
    "## Visualizaciones: ROC y matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y_prob_xgb' in globals():\n",
    "    RocCurveDisplay.from_predictions(y_test, y_prob_xgb)\n",
    "    plt.title('ROC Curve - XGBoost')\n",
    "    plt.show()\n",
    "\n",
    "if 'y_pred_xgb' in globals():\n",
    "    cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf97667",
   "metadata": {},
   "source": [
    "## Próximos pasos y mejoras sugeridas\n",
    "\n",
    "- Probar modelos basados en transformers (ClinicalBERT / DistilBERT) con `transformers` de Hugging Face.\n",
    "- Añadir features demográficas o clínicos y combinarlas con texto (FeatureUnion).\n",
    "- Evaluación clínica robusta: sensibilidad/especificidad en umbrales clínicos.\n",
    "- Despliegue: crear una app con Streamlit para demo.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
